---
date: '02/10/2026'
title: Signalling credible publications to editors
categories: [research, genAI]
published: true
---

Generative AI is removing the writing barrier to publication. Quality writing was one of the signals that editors and reviewers used to differentiate high quality from low quality work. But now its easy to produce low quality work that is well written. 

As AI slop becomes more ubiquitous the publication system will need to look for new signals for quality research. The quality of the data may be one signal. 

Author names and status may be another. 

News from the cybersecurity world provides an interesting hint as to how the future of publication may look. 

Many widely open source software packages allow for anyone to flag security flaws. Sometimes they offer bounties or rewards for identifying flaws. But genAI coding agents have flooded these projects with submissions, most of them AI slop. [This creates a huge burden on the software maintainers to manage and filter through those submissions](https://www.theregister.com/2026/01/21/curl_ends_bug_bounty/). 

[A recently proposed system for 'vouching'](https://simonwillison.net/2026/Feb/7/vouch/) allows the software maintainers to create a list of verified contributors. It effectively creates a list of allowed contributors to an open software project. If you aren't 'vouched' you are blocked from contributing. 

The issue with submissions on software security is much like the trends we are hearing about at peer-reviewed journals of increasing numbers of well-written but vacuous studies. 

So maybe in the near future we'll have to get our names on a white list before we can submit to reputable journals. 



