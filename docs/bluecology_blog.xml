<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Seascapemodels</title>
<link>https://www.seascapemodels.org/bluecology_blog.html</link>
<atom:link href="https://www.seascapemodels.org/bluecology_blog.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Tue, 21 Oct 2025 13:00:00 GMT</lastBuildDate>
<item>
  <title>Environmental impacts of large language models</title>
  <link>https://www.seascapemodels.org/posts/2025-10-22-environmental-impacts-LLMs/</link>
  <description><![CDATA[ 





<p>Just want to quickly highlight a few investigative blogs on the environmental impacts of LLMs.</p>
<p>There are two main issues: water use (for cooling servers) and carbon emissions generated by creating the hardware, training the models and then using the models to get responses (‘inference’).</p>
<p>This blog does a deep dive on the <a href="https://andymasley.substack.com/p/the-ai-water-issue-is-fake">water issues</a>. The key finding is that the water issues seem to be overstated (he says ‘fake’ but I don’t agree with that word choice, water issues are real, just overstated).</p>
<p>Then academic Hannah Ritchies and author of ‘Sustainability by Numbers’ page sums up the <a href="https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt">carbon cost of chatGPT</a>. She draws heavily on <a href="https://andymasley.substack.com/p/a-few-meta-points-on-my-posts-on">Andy Masley</a> detailed work.</p>
<p>In particular, blog author (<a href="https://www.andymasley.com/">Andy Masley</a>) argues that the public has limited attention span for environmental issues and AI isn’t the biggest priority. He sums it up nicely:</p>
<p>“AI water use is mostly fake, personal prompt costs are mostly fake, but AI as a whole is going to put a huge strain on our electrical grid going forward that’s going to matter a lot for the green energy transition, local electricity prices, and air pollution”</p>
<p>By fake, he means your personal usage is trivially small. He highlights golf courses and streaming videos as much larger uses of water and emissions respectively.</p>
<p>What also matters is the counterfactual - ie what would you be doing if you weren’t using chatGPT? If you would be online shopping, using a microwave or streaming videos instead, then your personal emissions are probably slightly lower if you switch your time to chatGPT.</p>
<p>If you are concerned about the impacts of your AI use you can easily do a personal offset by commiting to some simple behaviour changes. <a href="https://www.it.ox.ac.uk/article/reducing-energy-consumption-pcs">e.g.&nbsp;turn you computer off at night and turn it off at the power plug</a>.</p>
<section id="what-about-coders" class="level2">
<h2 class="anchored" data-anchor-id="what-about-coders">What about coders?</h2>
<p>One unaddressed question in these posts is the personal impacts of genAI power users (like me). By that I mean people using it for coding. The blogs above deal with people who are doing the occaisonal short chatGPT prompt. Coders might be leaning on AI hundreds of times a day for prompts that range from short to very long (and more energy intensive).</p>
<p>That’s something I’d like to do the numbers for later on.</p>


</section>

 ]]></description>
  <category>research</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-22-environmental-impacts-LLMs/</guid>
  <pubDate>Tue, 21 Oct 2025 13:00:00 GMT</pubDate>
</item>
<item>
  <title>modelbased package for plotting interactions</title>
  <link>https://www.seascapemodels.org/posts/2025-10-21-modelbased/</link>
  <description><![CDATA[ 





<p>I’ve been a big fan of the <code>visreg</code> package for a while, it makes it convenient to plot predictions from models. But recently I was struggling with a model that had many two-way interactions terms.</p>
<p>I checked out the key alternative to <code>visreg</code>, <code>ggeffects</code>, which is very popular (the paper has over 2000 citations). But the <code>ggeffects</code> page states it will be superseded by the <a href="(https://easystats.github.io/modelbased/)"><code>modelbased</code> package</a>. So here’s a quick demo of how to use <code>modelbased</code> to plot interaction effects from a GLM.</p>
<p><code>modelbased</code> is part of an ecosystem of packages for handling statistical models: <a href="https://easystats.github.io/modelbased/reference/estimate_slopes.html#references"><code>easystats</code></a>.</p>
<p>First I’m going to load data on coral cover and fish abundance from my <a href="https://github.com/cbrown5/example-ecological-data">Example ecological data</a> repo:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(dplyr)</span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'dplyr'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:stats':

    filter, lag</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(easystats)</span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<pre><code># Attaching packages: easystats 0.7.5 (red = needs update)
✔ bayestestR  0.17.0   ✔ correlation 0.8.8 
✖ datawizard  1.2.0    ✔ effectsize  1.0.1 
✔ insight     1.4.2    ✔ modelbased  0.13.0
✖ performance 0.15.1   ✔ parameters  0.28.2
✔ report      0.6.1    ✔ see         0.12.0

Restart the R-Session and update packages with `easystats::easystats_update()`.</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(readr)</span>
<span id="cb7-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load data from https://github.com/cbrown5/example-ecological-data</span></span>
<span id="cb7-3"></span>
<span id="cb7-4">dat_url <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/cbrown5/example-ecological-data/refs/heads/main/data/benthic-reefs-and-fish/fish-coral-cover-sites.csv"</span></span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Convert counts of coral to proportions</span></span>
<span id="cb7-7">dat <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_csv</span>(dat_url) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(</span>
<span id="cb7-9">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cb_cover =</span> cb_cover <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> n_pts, </span>
<span id="cb7-10">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">soft_cover =</span> soft_cover <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> n_pts</span>
<span id="cb7-11">    ) </span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 49 Columns: 13</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (2): flow, logged
dbl (11): site, reef.id, pres.topa, pres.habili, secchi, coordx, coordy, cb_...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
</div>
<p>Now we’ll fit a simple poisson GLM. <code>pres.topa</code> is count of topa fish, a fish that likes to live in branching corals (<code>cb_cover</code>), and <code>logged</code> is a binary variable indicating whether the site was near to logging or not (which causes pollution that harms fish and corals).</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">m1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">glm</span>(pres.topa <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> cb_cover <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>  logged,</span>
<span id="cb10-2">          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> dat,</span>
<span id="cb10-3">          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">family =</span> poisson)</span>
<span id="cb10-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(m1)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = pres.topa ~ cb_cover * logged, family = poisson, 
    data = dat)

Coefficients:
                          Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                 -3.839      1.124  -3.415 0.000639 ***
cb_cover                     8.691      1.979   4.392 1.12e-05 ***
loggedNot logged             5.313      1.136   4.675 2.93e-06 ***
cb_cover:loggedNot logged   -7.830      2.017  -3.882 0.000104 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 426.61  on 48  degrees of freedom
Residual deviance: 265.33  on 45  degrees of freedom
AIC: 353.22

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<p>It simple to then plot the interaction effects. I’m going to do so on <code>link</code> scale (log scale for poisson models):</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">pr <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cb_cover"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"logged"</span>),</span>
<span id="cb12-2">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>,</span>
<span id="cb12-3">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(pr) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb12-7">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hard coral cover"</span>,</span>
<span id="cb12-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Predicted Topa abundance (log scale)"</span>,</span>
<span id="cb12-9">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Soft coral cover"</span>, </span>
<span id="cb12-10">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Soft coral cover"</span></span>
<span id="cb12-11">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>  </span>
<span id="cb12-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_classic</span>()</span></code></pre></div></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.seascapemodels.org/posts/2025-10-21-modelbased/index_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>One neat thing that <code>modelbased</code> does is give you different options for how to estimate marginal means. The default is “typical”, which estimates marginal means at the average value of numerical predictors and averages over frequencies of categorical predicotrs. But you can also do “average” which averages over sample distributions and “population” which attemps to create a counterfactual for all possible combinations of variables.</p>
<p>These answer different questions, see the <a href="https://easystats.github.io/modelbased/reference/estimate_means.html">documentation for more details</a>.</p>
<p>I’m going to make a dataframe of all three methods so we can compare them:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1">pr_typical <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cb_cover"</span>,</span>
<span id="cb13-2">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>,</span>
<span id="cb13-3">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb13-4"></span>
<span id="cb13-5">pr_average <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m1, </span>
<span id="cb13-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cb_cover =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unique</span>(dat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>cb_cover)),</span>
<span id="cb13-7">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"average"</span>,</span>
<span id="cb13-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb13-9"></span>
<span id="cb13-10">pr_population <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cb_cover"</span>),</span>
<span id="cb13-11">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"population"</span>,</span>
<span id="cb13-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb13-13"></span>
<span id="cb13-14">pr_all <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bind_rows</span>(</span>
<span id="cb13-15">    pr <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical by logging"</span>),</span>
<span id="cb13-16">    pr_typical <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>),</span>
<span id="cb13-17">    pr_average <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"average"</span>),</span>
<span id="cb13-18">    pr_population <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"population"</span>)</span>
<span id="cb13-19">)</span></code></pre></div></div>
</div>
<p>Now we plot them:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(pr_all, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> cb_cover, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> Mean, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> logged)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb14-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb14-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_linerange</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> CI_low, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> CI_high)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb14-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>method) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb14-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb14-6">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hard coral cover"</span>,</span>
<span id="cb14-7">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Predicted Topa abundance (log scale)"</span>,</span>
<span id="cb14-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Logged"</span></span>
<span id="cb14-9">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>  </span>
<span id="cb14-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_classic</span>()</span></code></pre></div></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.seascapemodels.org/posts/2025-10-21-modelbased/index_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>And one more plot just of population and typical to more easily see the diffence:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1">pd <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">position_dodge</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>)</span>
<span id="cb15-2">pr_all <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(method <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"population"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(., <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> cb_cover, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> Mean, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> method)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position =</span> pd) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_linerange</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> CI_low, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> CI_high), </span>
<span id="cb15-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position =</span> pd) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb15-9">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hard coral cover"</span>,</span>
<span id="cb15-10">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Predicted Topa abundance (log scale)"</span>,</span>
<span id="cb15-11">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Logged"</span></span>
<span id="cb15-12">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>  </span>
<span id="cb15-13">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_classic</span>()</span></code></pre></div></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.seascapemodels.org/posts/2025-10-21-modelbased/index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>You can see see some key differences. The typical method shows effects of hard coral cover for a typical observation. There are slightly more unlogged than logged sites in the data:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">table</span>(dat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>logged)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Logged Not logged 
        21         28 </code></pre>
</div>
</div>
<p>So the typical sample is different from a balanced population level average.</p>
<p>The population and typical predictions fall in between the predictions that are conditional on logging status, because both are kinds of averages over the two logging categories.</p>
<p>Predictions from the ‘average’ method show an inconsistent pattern, because they are averaging over samples. You can roughly see the trends for logged and unlogged sites.</p>
<p>Finally, let’s convince ourselves that the unbalanced data is causing these differences. I’m going to randomly remove some unlogged sites to create a balanced dataset, and refit the model:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#randomly remove 7 'Not logged' sites to create balance</span></span>
<span id="cb18-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">707</span>)</span>
<span id="cb18-3">irm <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which</span>(dat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>logged <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Not logged"</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb18-4">dat2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> dat[<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>irm, ]</span>
<span id="cb18-5"></span>
<span id="cb18-6">m2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">glm</span>(pres.topa <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> cb_cover <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>  logged,</span>
<span id="cb18-7">          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> dat2,</span>
<span id="cb18-8">          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">family =</span> poisson)</span>
<span id="cb18-9"></span>
<span id="cb18-10">pr_typical2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m2, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cb_cover"</span>,</span>
<span id="cb18-11">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>,</span>
<span id="cb18-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb18-13"></span>
<span id="cb18-14">pr_population2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">estimate_means</span>(m2, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cb_cover"</span>),</span>
<span id="cb18-15">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"population"</span>,</span>
<span id="cb18-16">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link"</span>)</span>
<span id="cb18-17"></span>
<span id="cb18-18">pr_all2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bind_rows</span>(</span>
<span id="cb18-19">    pr_typical2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"typical"</span>),</span>
<span id="cb18-20">    pr_population2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"population"</span>)</span>
<span id="cb18-21">)</span>
<span id="cb18-22"></span>
<span id="cb18-23">pd <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">position_dodge</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>)</span>
<span id="cb18-24"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(pr_all2, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> cb_cover, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> Mean, </span>
<span id="cb18-25">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> method)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb18-26">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position =</span> pd) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb18-27">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_linerange</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> CI_low, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> CI_high),</span>
<span id="cb18-28">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position =</span> pd) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb18-29">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb18-30">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hard coral cover"</span>,</span>
<span id="cb18-31">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Predicted Topa abundance (log scale)"</span>,</span>
<span id="cb18-32">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Logged"</span></span>
<span id="cb18-33">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>  </span>
<span id="cb18-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_classic</span>()</span></code></pre></div></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.seascapemodels.org/posts/2025-10-21-modelbased/index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>You can see the two types of predictions are identical with balanced data.</p>



 ]]></description>
  <category>rstats</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-21-modelbased/</guid>
  <pubDate>Mon, 20 Oct 2025 13:00:00 GMT</pubDate>
</item>
<item>
  <title>Forage fish fisheries and marine predators</title>
  <link>https://www.seascapemodels.org/posts/2025-10-14-forage-fish-seabirds/</link>
  <description><![CDATA[ 





<p>Below are some links for my class on this topic</p>
<p><a href="https://www.seascapemodels.org/connections-game/forage-fish">Word match game quiz</a></p>
<ul>
<li>Match sets of four words.</li>
<li>When you’ve picked four words hit ‘submit’ to see if you are correct.</li>
<li>You get four guesses</li>
<li>Refresh your browser to start again</li>
<li>When you’ve completed each quiz, click ‘next level’ for the next quiz.</li>
</ul>
<p><a href="https://www.seascapemodels.org/seabird-block-game/">Seabird block game</a></p>
<ul>
<li>Move your seabird around to catch enough fish to lay an egg, then raise the chick to fledging.</li>
</ul>



 ]]></description>
  <category>research</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-14-forage-fish-seabirds/</guid>
  <pubDate>Mon, 13 Oct 2025 13:00:00 GMT</pubDate>
</item>
<item>
  <title>Resource for using Large Language Model tools in R</title>
  <link>https://www.seascapemodels.org/posts/2025-10-06-llm-tools-for-r-book/</link>
  <description><![CDATA[ 





<p>If you’re interested in using Large Language Models (LLMs) with R, you should check out Luis D. Verde Arregoitia’s new online resource: <a href="https://luisdva.github.io/llmsr-book/index.html">Large Language Model tools for R</a>. Its available in English and Spanish.</p>
<p>The resouce provides a comprehensive guide to working with LLMs in R, covering packages, techniques, and practical applications.</p>
<p>This is a great complement to my <a href="https://www.seascapemodels.org/AI-assistants-for-scientific-coding/">workshop and book</a> that guides you through some of the options and prompt engineering for high quality R analyses.</p>
<p>If you’re looking to integrate AI capabilities into your R workflows, this book is definitely worth exploring.</p>
<p>Check it out: <a href="https://luisdva.github.io/llmsr-book/index.html">https://luisdva.github.io/llmsr-book/index.html</a></p>



 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-06-llm-tools-for-r-book/</guid>
  <pubDate>Sun, 05 Oct 2025 13:00:00 GMT</pubDate>
</item>
<item>
  <title>New online book AI Assistants for Scientific Coding</title>
  <link>https://www.seascapemodels.org/posts/2025-10-05-AI-assistants-for-scientific-coding/</link>
  <description><![CDATA[ 





<p>I’ve released a new online book, <a href="https://www.seascapemodels.org/AI-assistants-for-scientific-coding/">AI Assistants for Scientific Coding</a>. It’s a practical guide to using language models to support scientific computing and analysis.</p>
<p>The book focuses on helping people who already use R or Python for data analysis. It’s not an introduction to programming; instead, it shows how to work with AI tools effectively and responsibly once you know the basics.</p>
<p>What you’ll find inside:</p>
<ul>
<li>Choosing and using AI coding assistants, from simple chat tools to agents that can run and test code</li>
<li>Prompting strategies that improve reliability for real analysis tasks</li>
<li>Examples from environmental science (GLMs, multivariate stats), with methods general to other fields</li>
<li>Notes on ethics, copyright, costs, and environmental impacts</li>
</ul>
<p>Read it here: https://www.seascapemodels.org/AI-assistants-for-scientific-coding/</p>
<p>The material also serves as reference notes for a one‑day workshop and will evolve as the field changes. If you’re interested in the prompting side of statistical workflows, there’s an accompanying preprint: https://doi.org/10.32942/X2CS80</p>



 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-05-AI-assistants-for-scientific-coding/</guid>
  <pubDate>Sat, 04 Oct 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Automating the Github Copilot Agent from the command line with Copilot CLI</title>
  <link>https://www.seascapemodels.org/posts/2025-10-04-running-github-copilot-CLI-agents-from-R/</link>
  <description><![CDATA[ 





<p><a href="https://docs.github.com/en/copilot/concepts/agents/about-copilot-cli">Github Copilot CLI (Command Line Interface)</a> recently became available. It is an AI agent, meaning it can use tools autonomously in a loop. It has two modes:</p>
<ol type="1">
<li><p>An interactive mode that is like a terminal version of the Copilot agent that runs in the chat window</p></li>
<li><p>A programmatic mode that can be run with shell scripts.</p></li>
</ol>
<p>The Copilot CLI is available with paid versions of github copilot.</p>
<p>The programmatic mode interested me, because it allows you to write scripts that call github copilot agents. This means you could run replicate agents on the same problem, then gather there results for analysis.</p>
<p>I, of course, want to do everything from the R program, because I’m not great with unix code or Python. <a href="https://docs.github.com/en/copilot/how-tos/set-up/install-copilot-cli">Once you’ve setup the copilot CLI</a>, its very easy to run it from R:</p>
<pre><code>
copilot_cmd &lt;- "copilot -p 'Set-up this project directory with a readme.md file, and directories for outputs, scripts, plots.' --allow-all-tools"

system(copilot_cmd)
</code></pre>
<p>This will run the agent autonomously in the current working directory of your R session.</p>
<p>Now I wouldn’t recommend using <code>--allow-all-tools</code> like this however. <a href="https://docs.github.com/en/copilot/concepts/agents/about-copilot-cli#security-considerations">There are important security considerations</a>. Like prompt injection attacks where an Agent goes on the web and gets tricked into doing something bad to your computer when it reads some malicious content. Likewise, agents can just stuff up and just delete or overwrite a bunch of files you wanted to keep.</p>
<p>You do need to allow some tools however, otherwise you might as well run the agent in interactive mode (because you’ll have to manually approve every tool use). This defeats the time-saving goal of running agents in a loop.</p>
<p>Here’s my current set-up:</p>
<p><code>copilot -p 'A prompt here' --allow-all-tools --deny-tool 'shell(cd)' --deny-tool 'shell(git)' --deny-tool 'shell(pwd)' --deny-tool 'fetch' --deny-tool 'extensions' --deny-tool 'websearch' --deny-tool 'githubRepo'"</code></p>
<p>I allow all tools, then prevent tools related to changing working directory, accessing the web or viewing directory context.</p>
<p>There is still some risk here. e.g., if you want it to run Rscripts you might want to include in your prompt something like ‘Use <code>Rscript my-script.R</code> to run R scripts from the terminal.’ The R scripts could include anything (including connecting to the web).</p>
<p>Here’s an example in action. I use sprintf to format the terminal command with the prompt, tools and sub-directory path.</p>
<pre><code>copilot_prompt &lt;- "Set-up this project directory with a readme.md file, and directories for outputs, scripts, plots. Then create example data to illustrate a poisson GLM. Make prediction plots. Use `Rscript 'my-script.R'` to run R files. "

copilot_tools &lt;- "--allow-all-tools --deny-tool 'shell(cd)' --deny-tool 'shell(git)' --deny-tool 'shell(pwd)' --deny-tool 'fetch' --deny-tool 'extensions' --deny-tool 'websearch' --deny-tool 'githubRepo'"

subdir_path &lt;- "dir1"

 copilot_cmd &lt;- sprintf(
    "cd '%s' &amp;&amp; copilot -p '%s' %s",
    subdir_path,
    copilot_prompt,
    copilot_tools
  )

system(copilot_cmd)
</code></pre>
<p>From here it would be easy to create a loop over different subdirectory paths, and run a separate agent in each one. The advantage of <code>cd</code>ing into each path before the agent opens is that the agent can’t then see context from other sub-directories. So you get independent agent runs.</p>
<p>You could use this to see how different prompts perform, or do complex prompt strategies like ‘tree of thought’. In tree of thought you ask an agent to create the same thing many times, it will do it slightly differently each time. Then you aggregate the results and pick the most common or most accurate one.</p>
<p>My one gripe is that Github have provided us with woeful documentation of what the tool names are. I’m guessing the tools are what you can see if you open the chat window, click ‘Agent’ mode, then click the tool symbol.</p>
<p>I’d love to have some default tool sets that simplify the tool permissions. For instance a tool set that locks down all web access.</p>



 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-04-running-github-copilot-CLI-agents-from-R/</guid>
  <pubDate>Fri, 03 Oct 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Planning an effective workshop</title>
  <link>https://www.seascapemodels.org/posts/2025-10-02-running-an-effective-workshop/</link>
  <description><![CDATA[ 





<p>This week in lab meeting we discussed planning a workshop. Here are a few notes of pointers that came up in the discussion.</p>
<p>Be clear on your goals for the workshop. And communicate those goals to the participants.</p>
<p>Invite the right people.</p>
<p>Think about what’s in it for them and communicate that in your invitation but also in follow-up communication. - Interesting places - Networking - Opportunity to collaborate - Opportunity to promote their own work</p>
<p>Think about what knowledge workshops participants need that they don’t currently have. This is particularly important if your workshop participants come from different disciplines.</p>
<p>You’ll need to plan to balance the delivery of essential information and the discussion to develop new ideas and obtain information from the group. For instance, what background info that is needed to participate effectively? What can individuals contribute? What synergies do you hope to get out of group discussions? (and making sure those people have the opportunity to talk together in the workshop).</p>
<section id="roles" class="level2">
<h2 class="anchored" data-anchor-id="roles">Roles</h2>
<p>For each workshop you should designate a facilitator and a note keeper. These should be different people. See also <a href="https://www.seascapemodels.org/research/2025/08/21/quick-tips-for-faciltating-meetings.html">our blog on facilitating meetings</a></p>
<p>Facilitation takes practice and its good to have someone experienced in this role.</p>
<p>You also need a plan to capture information from the workshop. So make sure you have a note taking system (e.g.&nbsp;online docs, charts on butcher’s paper) and someone who is going to chase those up from the group. Break-out groups are great, but make sure you have a way to capture their ideas.</p>
</section>
<section id="icebreakers-and-team-bonding" class="level2">
<h2 class="anchored" data-anchor-id="icebreakers-and-team-bonding">Icebreakers and team bonding</h2>
<p>You can send a form in advance asking a few questions about people’s backgrounds, as well as 1 or 2 questions about them as a person. Here’s some ideas - What is your area of research? - What paper or research product are you most proud of? - What are you hoping to get out of this workshop? - What is your favourite sport or hobby?</p>
<p>Plan an activity or activities to help people bond. One example is showing people a picture of a cloud. Then asking them to draw what they see in the cloud and share that with people nearby. Helps get people engaged in the workshop as well as understand that everyone has a different perspective. There are many different examples of these types of group bonding activities.</p>
<p>Another is ‘four corners’ or ‘two-sides’. Ask people to sort themselves in the room based on their preferences (keeping it non-political and light hearted). e.g.&nbsp;“Do you like mushrooms?”, “Do you like pineapple on pizza?”, “Are you an experimental, field or modelling scientist?”, …</p>
</section>
<section id="workshop-activities" class="level2">
<h2 class="anchored" data-anchor-id="workshop-activities">Workshop activities</h2>
<p>Strongly recommend using break-out groups, especially if you have more than 6 people at your workshop. This maximises engagement with the whole group and gives quieter voices a chance to speak up.</p>
<p>Think about the balance of plenary time (everyone together) and break out groups. A typical structure would be:</p>
<p>Opening presentation (plenary) Icebreaker (breakouts) Presentation on essential background (plenary) Set a task (plenary) Do the task (breakouts) Report back to the group on task (plenary) ….</p>
<p>Try to include a mix of different modes of activities to keep people energized and engaged. This can include discussion, working on charts/flow diagrams on butchers paper, online tools, other types of activities that require people to move around like ‘four corners’.</p>
</section>
<section id="planning-for-after-the-workshop" class="level2">
<h2 class="anchored" data-anchor-id="planning-for-after-the-workshop">Planning for after the workshop</h2>
<p>Make sure you communicate a plan for next steps at the end of the workshop, as well as in follow-up email.</p>
<p>Being clear on what is happening next, having a plan for next steps. When can participants expect to hear from the organizers? What are the outcomes (a manuscript perhaps)?</p>
<p>If you are writing a manuscript, then being clear on who will be included as a coauthor and what the requirements for coauthorship will be.</p>


</section>

 ]]></description>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-10-02-running-an-effective-workshop/</guid>
  <pubDate>Wed, 01 Oct 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Generative AI and R workshops in Hobart Australia</title>
  <link>https://www.seascapemodels.org/posts/2025-09-18-ai-r-workshops/</link>
  <description><![CDATA[ 





<p>In person Hobart Australia 11th and 12th November 2025</p>
<p><a href="https://www.seascapemodels.org/CMS-R-workshop/">Course page and further details</a></p>
<section id="registration" class="level2">
<h2 class="anchored" data-anchor-id="registration"><a href="https://payments.utas.edu.au/Register/booking?UDS_ACTION=S1I&amp;UDS_ACTION_DATA=bFAgA0dNWAFOKFdyNEJDBShXQg1KKE0bKUcyXAE1VDR7NVtc">Registration</a></h2>
<p>The R program is a powerful tool for data analysis, but has a steep learning curve. Join us for a 2-day workshop that will accelerate your R skills. Our modern approach to teaching leverages AI to help you create analyses with natural language, and code with fewer errors, but higher accuracy.</p>
<p>Presenter: A/Prof Chris J Brown c.j.brown@utas.edu.au Guest presenter: Professor Anthony Richardson, The University of Queensland and CSIRO Environment</p>
<p>Cost per day: $200 students, $300 professionals. Waiver available for indigenous scholars. Register for 1 or 2 days.</p>
</section>
<section id="day-1-11th-nov-quality-data-analysis-with-ai-coding-assistants" class="level2">
<h2 class="anchored" data-anchor-id="day-1-11th-nov-quality-data-analysis-with-ai-coding-assistants">Day 1 (11th Nov): Quality data analysis with AI coding assistants</h2>
<p>Suitable for R or Python users**. We’ll show you how to use large language models (like chatGPT) directly in your R or Python coding environment. You can accelerate your coding and get personalised help on your research. But there are risks, AI makes mistakes. We’ve developed guidelines to help you get the most out of AI for coding. We’ll also discuss the ethical implications of using AI to assist with research and whether ‘vibe coding’ is appropriate for scientists. This workshop is suitable for people with limited coding experience (e.g.&nbsp;can read data into Rstudio and make plots) as well as experts who want to know more about AI assistants.</p>
</section>
<section id="day-2-12th-nov-generalized-linear-models-in-r" class="level2">
<h2 class="anchored" data-anchor-id="day-2-12th-nov-generalized-linear-models-in-r">Day 2 (12th Nov): Generalized linear models (in R**)</h2>
<p>GLMs are a powerful tool for statistical analysis and prediction. We’ll teach the basics of the linear model and how it can be extended to all sorts of data in the generalized linear model. We’ll cover model verification, estimating effect size and significance and making predictions. The beauty of GLMs is that you only need some basic principles and you are ready to tackle many types of data, not like the old days when you had to know a different test for each new type of data.</p>
<ul>
<li>There may be additional subscription costs for AI software of up to USD20. Students can get free licenses. I will email instructions for getting software licenses prior to the workshops.</li>
</ul>
<p>**Note these workshops are not suitable for coding beginners. If you’ve never used R or Python before we suggest you take an introductory workshop. IMAS runs one, feel free to contact us for more info on that. As a rule of thumb, if you have Rstudio, know how to read data into R and make some plots you are ready for these workshops.</p>


</section>

 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-18-ai-r-workshops/</guid>
  <pubDate>Wed, 17 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>AI generated scicomm games</title>
  <link>https://www.seascapemodels.org/posts/2025-09-17-ai-generated-scicomm-games/</link>
  <description><![CDATA[ 





<p>This week I ran a talk and workshop for the Tasmanian Student Science Communicators Network.</p>
<p>The workshop was about creating gamifying learning. So I thought it would be fun to design some games then create them live as web apps using an AI agent.</p>
<p>The particpants designed games on a piece of paper. The aim was to communicate different concepts about sustainable management of fisheries through a game.</p>
<p>I then took the images and a simple description of game play and plugged it into the Roo Code AI agent.</p>
<p>Here’s the results, they are simple html and javascript based games.</p>
<p>Thanks to the workshop participants for generously contributing their ideas.</p>
<p>Here’s the links to the games and the game rules (which incidentally are also the prompts I used)</p>
<section id="fish-in-a-pond" class="level2">
<h2 class="anchored" data-anchor-id="fish-in-a-pond"><a href="https://www.seascapemodels.org/data/tassie-scicomm-games/fish-in-a-pond/">Fish in a pond</a></h2>
<p>In this game the player is working to replenish the fish population and racing a truck that is taking fish out of the ocean.</p>
<p>The ocean is the top bucket.</p>
<p>The bottom bucket is like candy candy crush. The player is trying to match four symbols. Every time they match a symbol new fish are born and top-up the fish in the ocean.</p>
<p>The game ends if the the ocean runs out of fish. If the player gets the fish over 80% full then the truck speeds up.</p>
</section>
<section id="fish-crush" class="level2">
<h2 class="anchored" data-anchor-id="fish-crush"><a href="https://www.seascapemodels.org/data/tassie-scicomm-games/fish-crush/">Fish crush</a></h2>
<p>In this game the player is to make a large amount of money. They are working to look after fish in a pond, then they catch the fish to make money.</p>
<p>They are aiming to keep the pond at about 50% full and have a profitable fishery.</p>
<p>They have to look after the environment around the pond so the fish are healthy. This means preventing pollution and making sure the water is good.</p>
<p>They can catch fish to make money. If they catch too many fish the population collapses.</p>
<p>Winning the game should require looking after the environment around the pond. It should also require catching fish at a slow steady rate, not too much, not too litte.</p>


</section>

 ]]></description>
  <category>genAI</category>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-17-ai-generated-scicomm-games/</guid>
  <pubDate>Tue, 16 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Projecting Uncertainty in Ecosystem Persistence Under Climate Change</title>
  <link>https://www.seascapemodels.org/posts/2025-09-13-projecting-uncertainty-ecosystem-persistence/</link>
  <description><![CDATA[ 





<p>Rising seas and coastal development are pushing mangrove forests beyond their historical limits. Predicting how these critical ecosystems will respond is much harder when environmental change is unprecedented. In a new study, <a href="https://doi.org/10.1111/gcb.70468">Projecting Uncertainty in Ecosystem Persistence Under Climate Change</a>, we show how to estimate the probability that mangrove forests will persist or decline worldwide.</p>
<p>Good predictions of ecosystem persistence are essential for coastal protection, fisheries management and climate-smart conservation planning.</p>
<p>The problem is that traditional models require detailed data that doesn’t exist at global scales. Models predict best when conditions match their training data. Climate change means mangroves face conditions they’ve never experienced before.</p>
<p>We developed a method to estimate probabilities of mangrove persistence using global datasets. This gives us a way to measure uncertainty that we can use to guide conservation decisions, e.g.&nbsp;to identify where management actions are most likely to succeed.</p>
<p>We used network models to analyze how mangroves respond at both their seaward and landward edges. Mangroves are unique because they can potentially expand in both directions as seas rise - landward into newly flooded areas, or seaward by trapping sediment.</p>
<p>Here’s the projections for persistence of mangroves as they are currently (ie without any loss) from one of our scenarios:</p>
<p><img src="https://www.seascapemodels.org/posts/2025-09-13-projecting-uncertainty-ecosystem-persistence/Buelow_etal2025-graphical-abstract.png" class="img-fluid"></p>
<p>Our models reveal a stark contrast. 77% of mangrove units worldwide are likely to lose area at their seaward edge by 2040-2060. Rising seas, storms and reduced sediment from dammed rivers create multiple pressures. In contrast, about 30% of units could gain area landward, but coastal development often blocks this migration.</p>
<p>Perhaps most importantly, uncertainty is high. In more than half the mangrove units studied, we couldn’t predict whether forests would persist or decline - the probability was essentially random. This isn’t a model failure. It tells us where better data and management actions could tip the balance.</p>
<p>Geographic patterns emerged clearly. Mangroves in areas with small tidal ranges face greater risks. Sediment-rich coastlines offer better prospects for seaward expansion. Areas with dense coastal populations face the greatest landward migration challenges.</p>
<p>We tested conservation scenarios and found encouraging results. With targeted management - sediment addition, barrier removal, and assisted migration - the number of units likely to persist could nearly double.</p>
<p>This research shows a new way to handle ecosystem predictions under climate change. Instead of false precision, we quantify what we know and don’t know. For mangroves, significant seaward losses are likely, but landward gains and conservation success remain possible with strategic action. Read more <a href="https://doi.org/10.1111/gcb.70468">here</a>.</p>



 ]]></description>
  <category>research</category>
  <category>modelling</category>
  <category>coastal-wetlands</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-13-projecting-uncertainty-ecosystem-persistence/</guid>
  <pubDate>Fri, 12 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Paper in a prompt creating a first draft in one prompt</title>
  <link>https://www.seascapemodels.org/posts/2025-09-12-creating-a-first-draft-in-one-prompt/</link>
  <description><![CDATA[ 





<p>*It was a rather long prompt</p>
<p>I wanted to see if I could get an AI agent to complete a first draft of a paper, including data analysis, searching for references on the web and writing a complete draft.</p>
<p>I used the Roo Code agent software with the Claude Sonnet 4.0 large language model.</p>
<p><a href="https://www.seascapemodels.org/data/ai-generated-manuscript">I’ve shared the results from replicate 1 here</a>.</p>
<p>I’ve also pasted the abstracts from the two replicates below. Both used identical prompts and settings in Roo Code. Its interesting how they are different. For instance the first one frames the study in terms of estimating the scale of human impacts. The second frames the study as being about studying an under-studied mechanism.</p>
<p>The experiment started with a project folder with data and detailed instructions for the research question, the data and the analyses I wanted. The instructions included details of R packages and specific statistics, for instance I told the model to use Bray-Curtis distances for the multivariate analysis.</p>
<p>I also provided basic instructions for how to write the paper. The agent had web search capabilities, allowing it to access , and read real references, and then incorporate insights from those into the paper.</p>
<p>It is important to note that this draft has not been edited by a human. Parts of it are not scientifically accurate. It should not be read as anything other than an experiment. It contains errors and some of the references are false.</p>
<p>For instance, it made up the following reference, but oddly linked it to a real reference (that is different) using a real DOI:</p>
<p>Hamilton, Richard J et al.&nbsp;2025. “Modeling Sediment Impacts on Juvenile Reef Fish.” Frontiers in Marine Science. https://doi.org/10.3389/fmars.2025.1513498.</p>
<p>It didn’t make much of an effort to create good instructions for writing a paper. I’m sure you could do a lot better than this with more careful prompting.</p>
<p>AI generated papers should never replace human oversight. If you rely solely on AI, you miss the chance to truly understand your subject. Science is about learning, not just producing content.</p>
<p>What this sort of thing could be useful for is as a way to iterate and quickly explore alternative options for how to write a paper, or explore alternative interpretations.</p>
<p>It can also help you get over ‘the fear of the white page’ (writers block), by giving you something to start editing.</p>
<section id="abstract-from-replicate-1" class="level2">
<h2 class="anchored" data-anchor-id="abstract-from-replicate-1">Abstract from replicate 1</h2>
<p>Terrestrial logging threatens coral reef ecosystems through increased sedimentation, yet the spatial patterns of impact remain poorly understood. We examined benthic community composition at 49 coral reef sites across a gradient of logging impacts in Kia Province, Solomon Islands, spanning distances from 0.20 to 22.4 km from logging operations. Using multidimensional scaling ordination and permutational multivariate analysis of variance, we tested for differences in community structure between logged and not logged sites and across distance categories. Benthic communities differed significantly between logged and not logged sites (PERMANOVA p = 0.027), with logged sites showing 14.2% lower coral cover (48.0% vs 62.2%). Distance-dependent effects were highly significant (p = 0.002), explaining 11.9% of community variance. Sites within 1 km of logging showed severely degraded conditions (31.2% coral cover, 33.3% sand cover), while sites beyond 10 km maintained high coral cover (62.9%). Recovery followed a clear gradient: moderate distance sites (1-3 km) had 55.3% coral cover, far sites (3-10 km) had 60.4% coral cover. Categorical distance analysis proved more informative than continuous distance relationships, indicating threshold effects rather than linear gradients. These findings demonstrate that logging impacts extend further than previously documented, with measurable effects at sites 1-3 km from operations. Our results provide quantitative evidence for establishing buffer zones around coral reefs and highlight the need for watershed-scale conservation planning that integrates terrestrial forest management with marine protected area design.</p>
</section>
<section id="abstract-from-replicate-2" class="level2">
<h2 class="anchored" data-anchor-id="abstract-from-replicate-2">Abstract from replicate 2</h2>
<p>Coral reef ecosystems face increasing threats from terrestrial activities, with logging-induced sedimentation representing a significant but understudied impact mechanism. This study examined benthic community structure across 49 coral reef sites in the Solomon Islands using multidimensional scaling (MDS) ordination to test the hypothesis that logging activities influence reef community composition through sedimentation. We applied non-metric multidimensional scaling to benthic cover data using both Euclidean and Bray-Curtis distance metrics, with environmental vector fitting to identify ecological gradients. The analysis revealed strong community gradients primarily associated with coral branching cover (r² = 0.82) and soft coral cover (r² = 0.62), while water clarity showed moderate correlation (r² = 0.24) with community structure. Contrary to expectations, distance to logging showed weak correlation with community patterns (r² = 0.056, p = 0.101), suggesting that logging impacts operate through pathways not captured by simple proximity measures. The results demonstrate MDS ordination effectiveness for revealing coral community structure patterns while highlighting the complexity of logging-reef relationships in tropical marine systems.</p>


</section>

 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-12-creating-a-first-draft-in-one-prompt/</guid>
  <pubDate>Thu, 11 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>AI aided note taking</title>
  <link>https://www.seascapemodels.org/posts/2025-09-05-AI-aided-note-taking/</link>
  <description><![CDATA[ 





<p>This is my favourite workflow for note taking at the moment:</p>
<ol type="1">
<li><p>Voice record my thoughts to iphone with the recording app. I don’t take much care to speak clearly or in a structured way. I just blurt all my thoughts out into the recorder.</p></li>
<li><p>Press the transcript button and copy the text</p></li>
</ol>
<p>Then I either do:</p>
<p>3a. Paste into Copilot for Teams and prompt <code>Clean up this voice recording and organize it into notes that are arranged in a logical order. Use markdown format</code></p>
<p>Or</p>
<p>3b. Paste into Teams chat to myself for later. Later on my laptop paste the text into a markdown document and use Roo Code or Github Copilot with <code>Clean up this voice recording and organize it into notes that are arranged in a logical order. Use markdown format</code></p>
<p>In general I’m not a fan of AI note taking. The problem is if you take a document you didn’t write and then get AI to summarize it for you there is no mental energy. The mental energy is when you learn and synthesize ideas.</p>
<p>However, I feel differently about voice recordings, because the ideas are still going via my brain before they get to the AI. It also allows me to capture complex ideas that I may not get time to write down.</p>
<p>For example, I’ve used it while cleaning the house to get a blog idea down and then into a first draft. I used it while walking to an appointment to ‘write’ a first draft of the methods for a paper.</p>



 ]]></description>
  <category>research-skills</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-05-AI-aided-note-taking/</guid>
  <pubDate>Thu, 04 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Making the jump from PhD to Postdoc</title>
  <link>https://www.seascapemodels.org/posts/2025-09-04-making-the-jump-from-phd-to-postdoc copy/</link>
  <description><![CDATA[ 





<p>In our lab meeting today we talked about the transition from a PhD to a postdoc position. I’m sharing some of the advice from the lab and reflections here.</p>
<p>Thanks to Seascapes and CAT labs for sharing their thoughts.</p>
<p>This can be a hard transition to make. At the end of your PhD you should have a good level of confidence about your topic. But then a postdoc position will often be on a different research problem, use different methods or be working with a different network of scientists and stakeholders.</p>
<section id="tips-to-prepare-for-the-transition" class="level2">
<h2 class="anchored" data-anchor-id="tips-to-prepare-for-the-transition">Tips to prepare for the transition</h2>
<section id="metacognition" class="level3">
<h3 class="anchored" data-anchor-id="metacognition">Metacognition</h3>
<p>Metacognition is self-awareness of your thought processes. For research its particularly key to be self-aware of how you learn.</p>
<p>Understanding how to learn means you can quickly and more smoothly immerse yourself in a new research topic.</p>
<p>For PhD supervisors you can point out or ask questions to help students understand their own thought and learning processes. For example, one metacognition trick is to use analogy to solve a new problem.</p>
<p>Another skill is understanding how you learn (is it by reading, by talking to people, by doing? ). This can help you come to grips with a new topic if you know how to research it and what is the best way that works for you.</p>
<p>Exposing yourself to a broad range of different types of research (for me this meant attending the biology department seminar which ranged from fisheries topics I was interested in to neuroscience which could still be interesting though not directly relevant to my studies then).</p>
</section>
<section id="presentation-and-communication-skills" class="level3">
<h3 class="anchored" data-anchor-id="presentation-and-communication-skills">Presentation and communication skills</h3>
<p>These skills are just broadly useful in many careers and easy to translate.</p>
<p>Its one reason we practice <a href="https://www.seascapemodels.org/research/2025/08/21/quick-tips-for-faciltating-meetings.html">facilitation of meetings</a> in our lab meetings.</p>
<p>Things to think about in your PhD (or for supervisors) are to get a broad view on different ways of presenting information. Sometimes our PhDs are too focused on academic publications and presentations.</p>
<p>Read, and look for opportunities to write in other formats such as blogs, media releases, reports and policy briefs.</p>
<p>For presentations, take comms training (if its available), do media interviews if you get the chance. Participating in 3 Minute Thesis (3MT) is another great way to learn presentation skills that are highly transferable.</p>
</section>
<section id="learning-who-matters-and-who-you-report-to" class="level3">
<h3 class="anchored" data-anchor-id="learning-who-matters-and-who-you-report-to">Learning who matters and who you report to</h3>
<p>Lots of people will give you advice or directions. Some of it is good, some not so good. Understanding of reporting structures in your organisation is important so you can understand your role and what the organisation wants you to achieve.</p>
<p>In your postdoc you may have less autonomy in some ways than you had in your PhD. Often postdocs are funded to deliver a certain project outcome (e.g.&nbsp;for industry partner or government).</p>
<p>This will mean you need to better differentiate between helpful advisors and project leaders that you need to deliver too.</p>
<p>As you progress in your career its also important to learn more about institutional structures. For instance, your supervisor might report to a head of school who reports to a dean who reports to a pro-vice chancellor. You probably didn’t pay too much attention to this stuff in your PhD.</p>
<p>It becomes increasingly important to understand as you move up in your career.</p>
</section>
</section>
<section id="making-the-transition" class="level2">
<h2 class="anchored" data-anchor-id="making-the-transition">Making the transition</h2>
<section id="knowing-how-to-get-help" class="level3">
<h3 class="anchored" data-anchor-id="knowing-how-to-get-help">Knowing how to get help</h3>
<p>Find out how to get help and don’t be afraid to ask. Your new colleagues are usually happy to help.</p>
<p>It could be small things like how to navigate the financial reimbursement system. This can save you a lot of time.</p>
<p>Most universities and large institutions will also provide access to counselling and mental health care services, so take make the most of those if you are finding the new job or move stressful.</p>
</section>
<section id="learning-a-new-topic" class="level3">
<h3 class="anchored" data-anchor-id="learning-a-new-topic">Learning a new topic</h3>
<p>Don’t underestimate the time it takes to learn a new topic. So give yourself (and talk to your supervisor about having) time to learn the new topic.</p>
<p>And the final tip from the team was to read old papers, from 10, 20, 30 years ago or more. When you are approaching a new topic these papers give you essential background and are often simpler to understand. Its also helpful to understand the historical context of a new research field.</p>


</section>
</section>

 ]]></description>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-04-making-the-jump-from-phd-to-postdoc copy/</guid>
  <pubDate>Wed, 03 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Create reports and tutorials with generative AI from R</title>
  <link>https://www.seascapemodels.org/posts/2025-09-02-AI-reports-with-openrouter-and-r/</link>
  <description><![CDATA[ 





<p>Several AI model providers have integrated web search capabilities into their large language models. I was attempting to use these features via the R <code>ellmer</code> package. However, changes to LLMs are so frequent that <code>ellmer</code> isn’t keeping up.</p>
<p>I did get <code>ellmer</code> to run Perplexity’s Sonar web search model, however it didn’t provide me with the references, which are essential.</p>
<p>If you haven’t seen these AI generated reports, check out the example at the end. Its a useful way to get a quick literature summary or create bespoke R tutorials.</p>
<p>Here <a href="https://github.com/cbrown5/web-search-ai/blob/main/README.md">I’m just announcing a couple of simple R scripts that you can use to do web search powered AI reports with the Openrouter service.</a></p>
<p>I just created two functions (with the help of copilot of course), one that makes a call to the Openrouter API to send a question to a model. The second function processes the output (which is in JSON format) to make a nice qmd, with the references hyper-linked (be sure to check the url before clicking them, who knows what the AI will turn up!). From there you can render the qmd to get a pdf/word/html report.</p>
<p>The functions are easy to use. First <a href="https://github.com/cbrown5/web-search-ai/blob/main/perplexity-search-functions.R">download or copy these functions from my github</a>.</p>
<p>Note never trust any code from someone else that sends requests to LLMs! It could potentially include harmful prompts. I recommend reading all code that is sending prompts to LLMs just to be sure you know what it does.</p>
<section id="using-the-code-to-do-a-search-and-create-a-report" class="level2">
<h2 class="anchored" data-anchor-id="using-the-code-to-do-a-search-and-create-a-report">Using the code to do a search and create a report</h2>
<p>Once you have my two functions, you will need to <a href="https://www.seascapemodels.org/AI-assistants-for-scientific-coding/03-set-up.html#sec-apikeys">set-up your Openrouter API key</a> and save the key somewhere (e.g.&nbsp;you can use <code>usethis::edit_r_environ()</code> and save it in there like OPENROUTER_API_KEY=“MY-KEY-HERE”)</p>
<p>Here’s an example of using the function:</p>
<pre><code>library(httr)
library(jsonlite)

source("perplexity-search-functions.R")

openrouter_api_key &lt;- Sys.getenv("OPENROUTER_API_KEY")

user_message &lt;- "I want to learn how to use the NIMBLE package to fit autoregressive time-series models"

system_message &lt;- "You are a helpful AI agent who creates statistical analysis tutorials in R. 
        Rules: 
        1. Include text and examples of code in your responses. 
        2. Produce reports that are less than 10000 words."

#Send response to openrouter 
response &lt;- call_openrouter_api(
  openrouter_api_key,
  model = "perplexity/sonar-deep-research",
  system_message = system_message,
  user_message,
  search_context_size = "medium"
  #Options "low"  "medium", "high"
)

#Save the response as a qmd
save_response_as_qmd(response, "results/AR-models-in-NIMBLE.qmd")</code></pre>
</section>
<section id="inputs-for-the-llm" class="level2">
<h2 class="anchored" data-anchor-id="inputs-for-the-llm">Inputs for the LLM</h2>
<p>The user message is your prompt for searching. The system message sets the scope of how the report is created. Note that anything for the web search goes in the user message, not the system message <a href="https://docs.perplexity.ai/guides/prompt-guide">see the Perplexity guidelines for more info on prompting advice, its different than for regular LLMs</a>.</p>
<p>For example, another idea for a system prompt could be:</p>
<pre><code>system_message &lt;- "You are a helpful AI agent who creates summary reports of the scientific literature. 
        Rules: 
        1. Produce reports that are less than 2000 words.
        2. Include a Summary section that summarizes key research trends. "

user_message &lt;- "What are the impacts of climate warming on fish physiology documented in the peer-reviewed academic literature"
</code></pre>
<p><code>search_context_size</code> is meant to control how much effort it puts in, its hard to tell if that impacts results or not, see <a href="https://openrouter.ai/docs/features/web-search">openrouter’s docs for more information.</a>.</p>
</section>
<section id="model-choices" class="level2">
<h2 class="anchored" data-anchor-id="model-choices">Model choices</h2>
<p>Other models to try are:</p>
<ul>
<li><p><code>perplexity/sonar</code> for a simpler, cheaper searches, including citations.</p></li>
<li><p><code>perplexity/sonar-deep-research</code> For deeper, more expensive searches with citations and reasoning.</p></li>
<li><p><code>openai/o4-mini</code> Is another option, but doesn’t return citations.</p></li>
</ul>
<p>Explore the openrouter site for other web search enabled LLMs.</p>
</section>
<section id="customization" class="level2">
<h2 class="anchored" data-anchor-id="customization">Customization</h2>
<p>The <code>call_openrouter_api.R</code> function is a template for customizing, not a comprehensive framework for using the openrouter API. Its actually very easy to connect to LLMs from R (even though most examples online are in python or typscript). Here’s a basic template:</p>
<pre><code>library(httr)
library(jsonlite)
response &lt;- POST(
    url = "https://openrouter.ai/api/v1/chat/completions",
    add_headers(
      "Content-Type" = "application/json",
      "Authorization" = paste("Bearer", openrouter_api_key)
    ),
    body = toJSON(list(
      model = model,
      messages = list(
        list(
          role = "system",
          content = system_message
        ),  
        list(
          role = "user",
          content = user_message
        )
      )
    ), auto_unbox = TRUE),
    encode = "raw"
  )
</code></pre>
<p>The trick then is formatting the output, which is what my other function does (focussing on perplexities models).</p>
</section>
<section id="report-example" class="level2">
<h2 class="anchored" data-anchor-id="report-example">Report example</h2>
<p>Below is an example, I asked used the system prompt above and asked about fitting surplus production models (for fisheries science) with the NIMBLE package. Note one minor bug with my function converting qmd references to hyperlinks, it potential does R sub-scripts as well. Something to work on later. Here’s the AI report:</p>
<p>You can fit a <strong>surplus production model (SPM)</strong> with the NIMBLE package in R by writing the model in BUGS language, which NIMBLE extends, specifying your likelihood (e.g., production dynamics with catch data) and priors for the parameters, and then using NIMBLE’s MCMC capabilities to estimate the posterior distributions of parameters. Here is a stepwise approach with example code snippets:</p>
<ol type="1">
<li><strong>Specify the surplus production model in BUGS code</strong>:<br>
This typically models biomass ( B_t ) evolving over time according to a logistic growth or Gompertz model minus catches ( C_t ). For example, the Schaefer model can be expressed as:<br>
[ B_{t+1} = B_t + r B_t (1 - ) - C_t + _t ]<br>
where (r) is intrinsic growth rate, (K) is carrying capacity, and (_t) models process noise.</li>
</ol>
<pre><code>library(nimble)

# Define the model in BUGS syntax
spm_code &lt;- nimbleCode({
  # Priors for parameters
  r ~ dunif(0, 2)           # growth rate
  K ~ dunif(maxCatch, 10 * maxCatch)  # carrying capacity (expand as appropriate)
  sigma ~ dunif(0, 5)       # process noise SD

  B&lt;a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank"&gt;[1]&lt;/a&gt; ~ dunif(0, K)       # initial biomass
  
  for(t in 1:(nYears - 1)) {
    mu[t] &lt;- B[t] + r * B[t] * (1 - B[t]/K) - catch[t]
    B[t + 1] ~ dnorm(mu[t], sd = sigma)
  }
})</code></pre>
<ol start="2" type="1">
<li><strong>Prepare the data and constants</strong> (e.g., catch time series, number of years):</li>
</ol>
<pre><code>data &lt;- list(catch = catch_vector)  # your observed catches
constants &lt;- list(nYears = length(catch_vector), maxCatch = max(catch_vector))
inits &lt;- list(r = 0.5, K = max(catch_vector)*5, sigma = 0.1, B = rep(NA, length(catch_vector)))</code></pre>
<ol start="3" type="1">
<li><strong>Build, compile, and run the model with NIMBLE</strong>:</li>
</ol>
<pre><code># Create model object
spm_model &lt;- nimbleModel(spm_code, data = data, inits = inits, constants = constants)

# Compile model
c_spm_model &lt;- compileNimble(spm_model)

# Configure MCMC; default samplers are usually fine
mcmc_conf &lt;- configureMCMC(spm_model)
mcmc &lt;- buildMCMC(mcmc_conf)
c_mcmc &lt;- compileNimble(mcmc, project = spm_model)

# Run MCMC sampling
samples &lt;- runMCMC(c_mcmc, niter = 10000, nburnin = 2000, thin = 5)

# Check results
summary(samples)</code></pre>
<p>This workflow follows NIMBLE’s general approach of specifying hierarchical Bayesian models in an extended BUGS language, compiling fast C++ versions of the model and samplers, and running MCMC algorithms<a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank">[1]</a><a href="https://www.rdocumentation.org/packages/nimble/versions/1.3.0/topics/nimble-package" target="_blank">[2]</a><a href="https://github.com/nimble-dev/nimble" target="_blank">[4]</a><a href="https://r-nimble.org" target="_blank">[7]</a>. The key is coding the surplus production dynamics explicitly as state-transition equations with observation or process error as needed.</p>
<p>For clarity, here is a <strong>minimal example with dummy catch data</strong>:</p>
<pre><code>library(nimble)

catch_vector &lt;- c(100, 120, 90, 80, 110) # example catches

spm_code &lt;- nimbleCode({
  r ~ dunif(0, 2)
  K ~ dunif(maxCatch, 10 * maxCatch)
  sigma ~ dunif(0, 5)

  B&lt;a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank"&gt;[1]&lt;/a&gt; ~ dunif(0, K)
  for(t in 1:(nYears - 1)) {
    mu[t] &lt;- B[t] + r * B[t] * (1 - B[t]/K) - catch[t]
    B[t+1] ~ dnorm(mu[t], sd = sigma)
  }
})

data &lt;- list(catch = catch_vector)
constants &lt;- list(nYears = length(catch_vector), maxCatch = max(catch_vector))
inits &lt;- list(r = 0.5, K = max(catch_vector)*5, sigma = 0.1, B = rep(NA, length(catch_vector)))

spm_model &lt;- nimbleModel(spm_code, data = data, inits = inits, constants = constants)
c_spm_model &lt;- compileNimble(spm_model)

mcmc_conf &lt;- configureMCMC(spm_model)
mcmc &lt;- buildMCMC(mcmc_conf)
c_mcmc &lt;- compileNimble(mcmc, project = spm_model)

samples &lt;- runMCMC(c_mcmc, niter = 5000, nburnin = 1000, thin = 2)
print(summary(samples))</code></pre>
<p>This example models biomass dynamics probabilistically and fits parameters (r), (K), and noise level () given known catches using Bayesian inference.</p>
<p>If you want to implement maximum likelihood fitting instead, NIMBLE lets you compile the model and evaluate likelihoods for optimization, as demonstrated in tutorials<a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank">[1]</a>.</p>
<p>In summary: - <strong>Write your surplus production model in NIMBLE’s BUGS language</strong>, defining biomass dynamics, catch, and priors for parameters<br>
- <strong>Compile and run MCMC</strong> sampling in NIMBLE to fit the model<br>
- <strong>Extract posterior samples</strong> for growth rate, carrying capacity, biomass, and uncertainty<br>
- Optionally, use <strong>likelihood-based methods</strong> by compiling the model and defining your own optimizer function in R<a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank">[1]</a><a href="https://r-nimble.org" target="_blank">[7]</a>.</p>
<p>This approach leverages NIMBLE’s power for hierarchical, Bayesian time-series stock assessment models including surplus production models.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://oliviergimenez.github.io/banana-book/intronimble.html" target="_blank">oliviergimenez.github.io/banana-book/intronimble.html</a></li>
<li><a href="https://www.rdocumentation.org/packages/nimble/versions/1.3.0/topics/nimble-package" target="_blank">www.rdocumentation.org/packages/nimble/versions/1.3.0/topics/nimble-package</a></li>
<li><a href="https://www.youtube.com/watch?v=DE4Q82QgSBs" target="_blank">www.youtube.com/watch</a></li>
<li><a href="https://github.com/nimble-dev/nimble" target="_blank">github.com/nimble-dev/nimble</a></li>
<li><a href="https://r-nimble.org/documentation-2" target="_blank">r-nimble.org/documentation-2</a></li>
<li><a href="https://cran.r-project.org/web/packages/nimbleCarbon/vignettes/nimble_carbon_vignette.html" target="_blank">cran.r-project.org/web/packages/nimbleCarbon/vignettes/nimble_carbon_vignette.html</a></li>
<li><a href="https://r-nimble.org" target="_blank">r-nimble.org/</a></li>
<li><a href="https://www.rdocumentation.org/packages/nimble/versions/1.3.0" target="_blank">www.rdocumentation.org/packages/nimble/versions/1.3.0</a></li>
</ol>


</section>

 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-09-02-AI-reports-with-openrouter-and-r/</guid>
  <pubDate>Mon, 01 Sep 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Points to consider when framing a regional study for the international literature</title>
  <link>https://www.seascapemodels.org/posts/2025-08-21-points-framing-regional-study-international-literature/</link>
  <description><![CDATA[ 





<p>At lab meeting today we discussed how to take your regional study and frame it for the global literature. This framing is essential for engaging international audiences and navigating editors and reviewers when publishing in international journals.</p>
<p>Thanks to the Seascapemodels and Conservation Action Team labs at Utas and Griffith Uni for their contributions.</p>
<section id="foundational-principles" class="level2">
<h2 class="anchored" data-anchor-id="foundational-principles">Foundational Principles</h2>
<p><strong>1. Consider your audience</strong></p>
<p>If you’re targeting an international journal, your readers will be international scientists. They will be less interested in hearing about the specific organisms in your part of the ocean and more interested in understanding what your results mean for their own research contexts. Frame your findings in terms of broader ecological patterns, processes, or principles that transcend geographic boundaries.</p>
<p><strong>2. Establish global context through strategic citations</strong></p>
<p>Cite global studies and literature from multiple regions, not just your local area. Global studies are often well-cited because they provide the comparative framework that regional studies need. When citing studies from other regions, be strategic about which ones you include:</p>
<ul>
<li><strong>Choose contrasting systems</strong>: Select studies from regions with different environmental conditions (temperate vs.&nbsp;tropical, shallow vs.&nbsp;deep, pristine vs.&nbsp;degraded) to highlight what makes your system unique or generalizable.</li>
<li><strong>Include similar systems for comparison</strong>: Find studies from ecologically similar regions to show whether your findings represent broader patterns or regional anomalies.</li>
<li><strong>Reference methodological precedents</strong>: Cite studies that used similar approaches in other regions, even if the ecological focus differs, to establish the credibility of your methods.</li>
<li><strong>Draw from different disciplines</strong>: Include studies from related fields (e.g., terrestrial ecology, freshwater systems) when they provide relevant theoretical context or methodological insights.</li>
</ul>
<p>Position your region within this broader context by explicitly comparing and contrasting your findings with patterns observed elsewhere. For example: “While coral bleaching in the Caribbean typically occurs at 29°C, our Pacific sites showed bleaching at 31°C, suggesting regional adaptation to higher baseline temperatures.” This demonstrates that you understand the global state of knowledge and can articulate where your work fits.</p>
</section>
<section id="specific-framing-strategies" class="level2">
<h2 class="anchored" data-anchor-id="specific-framing-strategies">Specific Framing Strategies</h2>
<p><strong>3. Connect to established theories and frameworks</strong></p>
<p>Relate your case-study to general ecological theories or established analytical frameworks. For example, your work could be an application of the DPSIR (Drivers-Pressures-State-Impact-Response) framework to your region, or a test of the recruitment limitation hypothesis in a new system. This approach transforms your regional study from a descriptive account into a contribution to broader scientific understanding.</p>
<p><strong>4. Demonstrate novelty without claiming “firsts”</strong></p>
<p>State your contributions by explaining why your approach or findings matter, rather than simply claiming precedence. Avoid phrases like “this is the first time.” Instead, draw parallels to successful applications in other fields or regions. For example, rather than “This is the first time we’ve used machine learning for fisheries,” try “Machine learning has proven highly effective for predictions in agriculture and could provide similar benefits for fisheries management.”</p>
<p><strong>5. Highlight unique perspectives and unexpected findings</strong></p>
<p>Show how your case-study reveals new patterns or challenges existing assumptions compared to other regional studies. Focus on findings that offer fresh insights into well-studied processes. For example: “While marine heatwaves are known to cause widespread mortality, our study reveals that toxic plankton blooms can flourish during these events, creating compound ecological impacts.”</p>
<p><strong>6. Present methodological innovations</strong></p>
<p>Frame your work as developing or refining methodological approaches, with your regional study serving as a proof-of-concept. This strategy is particularly powerful when you’ve adapted techniques from other disciplines or combined existing methods in novel ways. Emphasize how the method could be applied in other regions or systems, making your local study a stepping stone to broader applications.</p>
</section>
<section id="practical-applications-and-impact" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications-and-impact">Practical Applications and Impact</h2>
<p><strong>7. Demonstrate real-world applications</strong></p>
<p>When conducting applied research, explicitly show how your science has been used for conservation or management decisions. One excellent example is Rick Hamilton’s <a href="https://www.sciencedirect.com/science/article/pii/S0006320721002925">turtle tracking paper</a>. While countless studies track turtles, Hamilton got his work published in an international conservation journal by demonstrating how the tracking data directly informed conservation actions. He also capitalized on a review highlighting that most tracking studies fail to influence conservation practice, establishing his work’s unique value.</p>
<p><strong>8. Connect to global goals and initiatives</strong></p>
<p>Link your research to internationally recognized objectives and frameworks. This connection is increasingly common and effective. For example: “SDG 14.4 aims to make fisheries sustainable by 2020. Achieving this goal requires better models of climate impacts on fish populations—precisely what our study provides.” Other relevant frameworks include the Convention on Biological Diversity targets, national biodiversity strategies, and organizational goals like those of the Global Mangrove Alliance. These connections help editors and reviewers understand your work’s broader significance.</p>


</section>

 ]]></description>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-08-21-points-framing-regional-study-international-literature/</guid>
  <pubDate>Wed, 20 Aug 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Quick tips for facilitating a good meeting</title>
  <link>https://www.seascapemodels.org/posts/2025-08-21-quick-tips-for-faciltating-meetings/</link>
  <description><![CDATA[ 





<p>In roughly chronological order.</p>
<p>This advice comes from perspective of trying to get contributions from diverse research groups, that often mix career stages and cultural backgrounds. But much of it is useful in any context (e.g.&nbsp;more formal contexts.)</p>
<section id="before-the-meeting-starts" class="level2">
<h2 class="anchored" data-anchor-id="before-the-meeting-starts">Before the meeting starts</h2>
<p><strong>Be prepared.</strong></p>
<ul>
<li>Try to learn participants names and something about their background.</li>
<li>Reflect on expectations participants might have for the meeting these might be in terms of outcomes, but also cultural expectations in terms of behaviour.</li>
<li>Set a meeting agenda. Send it around to participants ahead of time.</li>
<li>Send them any background reading ahead of time (but keep it short and assume that most haven’t read it)</li>
<li>Designate a note-taker (if needed). You can’t facilitate well and take notes.</li>
</ul>
<p>Show up early, so you can familiarise yourself with the room set-up.</p>
<p>If its online, familiarise yourself with the software features before the meeting (where chat box is, where Q&amp;A box is, what people see when you speak, is sharing enabled etc…)</p>
<p>Prepare your introductory and closing notes.</p>
<p>Check the agenda with someone more experienced if need be - people often try to cram too much into a meeting. One way to save meeting time for discussion is to pre-send reading for the group.</p>
</section>
<section id="starting-the-meeting" class="level2">
<h2 class="anchored" data-anchor-id="starting-the-meeting">Starting the meeting</h2>
<p>Come prepared with an opening that will set the scene and topic of the meeting. Remind people of the time slot for the meeting, and its goals. Remind them of expectations e.g.&nbsp;who is speaking, what to do if you disagree (if neccessary).</p>
<p>As facilitator people will look to you for leadership on how the meeting goes. Your approach will affect:</p>
<ul>
<li>how fast people talk</li>
<li>whether it is safe to pause between comments, or whether someone grabs that free air space and starts talking</li>
<li>who overtalks who</li>
<li>who talks; if its ok to talk if you are shy or less senior.</li>
</ul>
<p>If you don’t provide that leadership, then that role will default to the most senior person or the person who talks the most.</p>
<p>So grab your facilitator role by the reins and show the group how its going to be.</p>
</section>
<section id="during-the-meeting" class="level2">
<h2 class="anchored" data-anchor-id="during-the-meeting">During the meeting</h2>
<p>Be present. Keep on your toes. By this I mean actually listen to what other people are saying, rather than thinking about what you will say when other people talk.</p>
<section id="engaging-the-participants" class="level3">
<h3 class="anchored" data-anchor-id="engaging-the-participants">Engaging the participants</h3>
<p>Engaging everyone helps everyone feel heard and helps get contributions from all participants.</p>
<p>Show other people you are listening: eye contact, nodding, hand gestures.</p>
<p>Reflect back to people what they’ve just said. This is active listening. For instance, if Alice described how she was satisified with the progress on the project” you could respond “Thanks Alice, I see that you’re happy with how the project is going” (rather than just nodding).</p>
<p>Draw in people, especially the quiet ones. For instance, if Selena describes an issue she is having with the data analysis on the project you could hand it over to Takuya: “Takuya, I know you’ve written about network modelling, do you have experiences from that work you could share to help Selena”</p>
<p>If you don’t know their backgrounds that is ok to! You can just ask someone to reflect like: “Takuya, what do you think about what Selena just said” or “Takuya, can you describe the problem Selena is having in your own words?”</p>
<p>This reflection opportunity can be helpful to engage people, but also see problems from different perspectives.</p>
<p>If you start asking people to reflect on each other’s comments, everyone will pay more attention to what is being said.</p>
</section>
<section id="you-dont-need-to-have-all-the-answers" class="level3">
<h3 class="anchored" data-anchor-id="you-dont-need-to-have-all-the-answers">You don’t need to have all the answers!</h3>
<p>A common mistake as facilitator is to think you need to answer the questions that are posed. Then the facilitator ends up talking with their own answers. You don’t answer them.</p>
<p><strong>You are there to help the group find a solution.</strong> So if a problem/question comes up, use your facilitator skills to kick it onto someone else like “Muhammad, what do you think about Maria’s question?”</p>
<p>If the group solves a problem, even if you knew the answer, then you are doing successful facilitation.</p>
</section>
</section>
<section id="dealing-with-problems" class="level2">
<h2 class="anchored" data-anchor-id="dealing-with-problems">Dealing with problems</h2>
<section id="people-who-talk-too-much" class="level3">
<h3 class="anchored" data-anchor-id="people-who-talk-too-much">People who talk too much</h3>
<p>The tactful way is to smoothly transition the conversation away from them, by taking over their sentences. Its hard to put this in text but here goes:</p>
<p>Overtalker: “What I’m talking about is the absolute lack of data in…” Facilitator (finishes the sentence) “the models. That’s a really important insight John. I’d like to pass on to Eva for her perspective on this issue”.</p>
<p>But this is partly highly cultural. e.g.&nbsp;in some cultures the senior members need to be let to speak as much as they want, in other cultures it might be more appropriate to let minority groups speak first. Some cultures this is fast and seamless. Others you would leave a long pause between sentences.</p>
</section>
<section id="people-who-talk-too-much-in-online-meetings" class="level3">
<h3 class="anchored" data-anchor-id="people-who-talk-too-much-in-online-meetings">People who talk too much in online meetings</h3>
<p>This is really difficult. And we all tend to overtalk in online meetings because we aren’t getting as much visual feedback from our participants! If you have advice let me know. A couple tips:</p>
<ul>
<li>Get cameras turned on so people get more visual feedback.</li>
<li>Be engaged, overstate your body language (nodding etc…) so the speaker knows you are listening</li>
<li>Use emoticons and reactions</li>
</ul>
<p>Sometimes I just talk over them like in the ‘people who talk too much’ example. The key thing is to show you’ve heard by reflecting their thoughts back to them in your own words. If you abruptly change topics it may seem rude.</p>
</section>
<section id="people-who-dont-engage-or-who-are-shy" class="level3">
<h3 class="anchored" data-anchor-id="people-who-dont-engage-or-who-are-shy">People who don’t engage or who are shy</h3>
<p>See notes above about engaging particpants. Just try to be aware of who they are and keep a mental checklist of who is doing the talking.</p>
</section>
<section id="transitioning-the-conversation" class="level3">
<h3 class="anchored" data-anchor-id="transitioning-the-conversation">Transitioning the conversation</h3>
<p>What to do if the conversation is going in the wrong direction, or you are running out of time?</p>
<p>Follow above advice for people who talk too much to transition the conversation to where you want it to go.</p>
<p>Just remember to acknowledge the person you are taking the platform from. A bad example</p>
<p>“So we are running out of time, let’s move on”</p>
<p>Good example:</p>
<p>“Thanks for those important insights Anya. I think we need to follow-up to properly explore those ideas. Now I’d like to just take us back to the agenda…”</p>
</section>
<section id="strong-emotions-and-conflict" class="level3">
<h3 class="anchored" data-anchor-id="strong-emotions-and-conflict">Strong emotions and conflict</h3>
<p>Sometimes people express anger, frustration or deep sadness in meetings. Sometimes there is conflict that goes beyond healthy collegial debate. These situations can be difficult and need to be treated case-by-case, particularly if they involve ongoing issues in group dynamics.</p>
<p>The only general point I can make is to acknowledge the feelings. For example, you could say, “Rachael, are you feeling angry about what was just said?”</p>
<p>This helps the person feel heard. But also helps you take the floor back from the conflict.</p>
<p>How you go from there depends on the situation. If its sadness (like a colleague drops the news that they lost a friend recently) and you are in a supportive group, you could offer condolences and reflections as a group, just generally show kindness.</p>
<p>If its serious conflict yuo might like to ask the person to come outside for a private chat (and delegate facilitation to someone else while you are gone).</p>
<p>I’ll leave that there, as I am no expert on conflict resolution.</p>
</section>
</section>
<section id="save-time-to-wrap-up-and-finish-on-time" class="level2">
<h2 class="anchored" data-anchor-id="save-time-to-wrap-up-and-finish-on-time">Save time to wrap up and finish on time</h2>
<p>Its polite to finish on time. You should aim to finish early, to allow time to wrap up. Also people may have ‘last thoughts’ just when you were going to finish. For example for a 50 minute meeting start at 11am:</p>
<p>11:35am - Start bringing the conversation back to the agenda 11:40am - Ask for any last thoughts 11:45am - Provide wrap-up, reflection, next steps and actions.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>Save time to wrap-up the meeting. This can include:</p>
<ul>
<li>Reflections on key things that were discussed or learned</li>
<li>Acknowledging different people’s contributions</li>
<li>Thanking people for contributions, especially if they put a lot of effort in (e.g.&nbsp;planning) or brought up something that was emotionally difficult (like sharing a failure that the group can learn from)</li>
<li>Addressing the agenda items</li>
</ul>
<p>If it is an action orientated meeting, you should also finish by stating the next steps.</p>
</section>
<section id="online-meetings" class="level2">
<h2 class="anchored" data-anchor-id="online-meetings">Online meetings</h2>
<p>I much prefer in-person meetings. Online meetings are more less like conversations and more like he talks, she talks, he talks, she talks.</p>
<p>Meetings that are simultaneously online and in person are the worst.</p>
<p>A few tips:</p>
<ul>
<li>Delegate someone to be the ‘chat facilitator’. Their job is to keep an eye on the chat and bring any points to your attention. Some people won’t or can’t talk online and may type instead. So its still good for you as facilitator to raise their points like: “Ahhh, I see Caitie has asked a great question online, Alyssa she wants to know if…”</li>
<li>If it is simultaneously online and in person you need an ‘online’ faciliator to help bring in those people (remind you, monitor chat, perhaps talk to online participants directly)</li>
<li>Cameras on is better for engagement</li>
<li>Resist the temptation to check your email when other people are talking (I once did this with screen sharing on, oops). You need to be engaged and staying present.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Facilitation is a foundational skill for most careers. But few of us practice it or put much thought into it. It does take practice and commitment to do it well. But its also rewarding to see your team flourish and everyone get more out of meetings.</p>


</section>

 ]]></description>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-08-21-quick-tips-for-faciltating-meetings/</guid>
  <pubDate>Wed, 20 Aug 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>It’s getting harder to predict ecological change</title>
  <link>https://www.seascapemodels.org/posts/2025-08-13-validating-predictive-models/</link>
  <description><![CDATA[ 





<p>The increasing pace of climate change and human impacts on ecosystems is pushing ecosystems beyond the envelope of past conditions. The pace of change makes predicting that change much harder. In a new study, <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.70105">Assessing predictive accuracy of species abundance models in dynamic systems</a>, we show how to test model forecasts in rapidly changing ecosystems.</p>
<p>Good tests of model forecasts help us quantify uncertainty and are important for many management applications including fisheries stock forecasts, species extinction risk and climate-smart conservation planning.</p>
<p>The pace of change is a problem for making predictions because our models are trained on historical data. Model’s predict best when they are predicting to conditions they’ve ‘seen’ in the training data. Unprecedented environmental change means our models need to extrapolate. This is much harder.</p>
<p>One recent example is the deadly algal bloom across 500km of South Australia’s coast. No ones saw this coming. No-one yet knows if its likely to reoccur or not.</p>
<p>We developed a way to test models with historical data to get an idea of how well they extrapolate. This gives us a better measurement of model uncertainty that we can use to calibrate risk, e.g.&nbsp;to see how much we might be under-estimating extinction risk or overestimating fish stock size.</p>
<p>We illustrated our method with a 30 year timeseries of reef biota from Maria Island. We split this time-series into sections used for training and sections used for testing the model. The model is then fit to the training data and forecast to the testing data. The difference between its forecast and the test data is a measure of its errors.</p>
<p>Our new method forces the model to fit to ‘out-of-date’ data. Whereas, the typical method keeps the models contemporary to the testing data. g We confirmed that for a species with a population collapse our new method gives a much more pessimistic (broader) estimate of uncertainty than the typical method would do.</p>
<p>We suggest our method be used to better estimate risk measures when using models to forecast ecological change. Our method can also be used in meta-studies that are exploring how predictability varies across different species, places and times. This is a point we’ll pick up in our next study. Read more <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.70105">here</a>.</p>



 ]]></description>
  <category>research</category>
  <category>modelling</category>
  <guid>https://www.seascapemodels.org/posts/2025-08-13-validating-predictive-models/</guid>
  <pubDate>Tue, 12 Aug 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Writing scientific papers with quarto and AI assistants</title>
  <link>https://www.seascapemodels.org/posts/2025-07-07-writing-papers-with-quarto/</link>
  <description><![CDATA[ 





<p>Below is my suggested workflow for using quarto to write scientific papers. I’m currently switching to doing as many projects as possible with quarto rather than word for a few reasons:</p>
<ol type="1">
<li>Easier to manage document style</li>
<li>Easier to manage references</li>
<li>Workflows that auto-update figures/tables when R code is re-run</li>
<li>Generative AI integration that is customizable.</li>
</ol>
<p>Point 3 is great, no more cut and pasting figures into word documents!</p>
<p>Point 4 is the big one. I’m developing my own ‘writing mentor’ scripts for large language models. Using quarto lets me implement writing advice specific to science direclty into my manuscripts.</p>
<p>Quarto is ‘What You See is What you Make’, meaning that you write special syntax for formatting. Once you are used to it, this is way easier way to manage styles than word.</p>
<p>The downside is getting your (non-coding) collaborators to edit files in quarto. This is the biggest bottleneck to my use of quarto/markdown. Currently I send them word documents then have to manually integrate the feedback. Or I work in quarto until the near final stages, accepting comments only, then get them to edit the final manuscript.</p>
<p>For instance, <a href="https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/cobi.13079?casa_token=zF8vihnFfcMAAAAA%3A9WlbXPCghdwS2WvyRqGjRqYPrng7q4_xPwZvu9K52p6gd_8lWs2qcgrehfg4ehAThC7ni32Ybr02iA">I wrote most of this paper in markdown</a> but had to go to word editing towards the end so I could get edits from my collaborator. Once you’ve progressed it in word, its hard to go back to markdown.</p>
<p>Instructions below are high level. There are quite a few pieces of software you need to do this, so I’ve linked to tutorials for each below.</p>
<section id="download-and-install-an-ide" class="level3">
<h3 class="anchored" data-anchor-id="download-and-install-an-ide">1. Download and install an IDE</h3>
<p>Download and install VScode.</p>
<p><a href="https://www.seascapemodels.org/rstats/2025/06/12/setting-up-vscode-r-genAI.html">Instructions online e.g.&nbsp;here</a></p>
<p>I’m using VScode because of its AI assistant integration. But you could also use positron if you have issues with VScode or want to use a Posit product rather than a Microsoft product.</p>
</section>
<section id="get-git-and-github" class="level3">
<h3 class="anchored" data-anchor-id="get-git-and-github">2. Get git and github</h3>
<p>Install git on your computer. Optionally, get a github account and connect to that. Git does version control. Github lets you share that online. If your collaborators are github users then you can also share edits on documents this way.</p>
<p>Git is also essential if you are using AI assistants. Sometimes they majorly stuff up your documents. So keeping back ups with git is essential.</p>
</section>
<section id="vscode-extensions" class="level3">
<h3 class="anchored" data-anchor-id="vscode-extensions">3. VScode extensions</h3>
<p>Install these VScode extentions (or equivalents if you are using positron, note that many vscode extensions are also compatable with Positron)</p>
<ul>
<li>Quarto extension.</li>
</ul>
<p>Open VSCode and click the four boxes ‘extension’ icon on the LHS then search and install the Quarto extension.</p>
<p>Optional extensions: - R language extension (<a href="https://www.seascapemodels.org/rstats/2025/06/12/setting-up-vscode-r-genAI.html">can be tricky to connect VScode to R, suggest you web search for advice</a>)</p>
</section>
<section id="optional-steps-for-ai-integration" class="level3">
<h3 class="anchored" data-anchor-id="optional-steps-for-ai-integration">4. Optional steps for AI integration</h3>
<p>This next step is optional. If you are using quarto or markdown its possible to get large-language models to help with many paper writing tasks (including the writing). This is a specialized area though and I’ve only given basic technical instructions here. Actually getting it to work well is another topic altogether and something I’m still developing…</p>
<p>Get an API key with an LLM provider (e.g.&nbsp;<a href="https://openrouter.ai/sign-up">OpenRouter</a>, <a href="https://platform.openai.com/api-keys">OpenAI</a>, <a href="https://console.anthropic.com/login?returnTo=%2F%3F">Anthropic</a>). You’ll need a developer account to get an API key, rather than a regular account that you may already have (see links in last sentence). Buy some credits so you can use your API.</p>
<p>Make sure you save your API key somewhere safe! You can usually only view them once on creation. You’ll need it for the workshop.</p>
<p>Get the Roo Code extension for vscode/positron.</p>
<p><a href="https://docs.roocode.com/">Read the documents/watch the tutorials and learn how to use Roo Code</a></p>
<p>You can now <a href="https://docs.roocode.com/features/custom-modes">create a custom mode</a>, e.g.&nbsp;a ‘scientific writing mode’ in Roo code. As of writing this requires clicking the mode selection button at the bottom of the Roo Code Pane, then click the Cog, then the <code>+</code> button to make a new mode. Then you need to write a ‘Role Definition’ and ‘Custom instructions’. For tools I just use ‘Read Files’, ‘Edit Files’ and unclick the others (will save you money and tokens).</p>
<p>This is the hard part that needs a lot of thought:</p>
<p>In the custom instructions you should write detailed instructions on how to help an author with scientific writing. For instance, you might want to put some very strong instructions about not making up references. You might also put instructions about your particular writing style preferences. I’m working on a template, but am not yet ready to share it.</p>
<p>See <a href="https://docs.roocode.com/features/custom-modes">Roo code documentation</a> for more advice on custom modes.</p>
</section>
<section id="using-quarto" class="level3">
<h3 class="anchored" data-anchor-id="using-quarto">5. Using quarto</h3>
<p>Take a tutorial and <a href="https://quarto.org/docs/get-started/hello/rstudio.html">learn how to use Quarto</a>.</p>
<p>For academic paper writing the key things to understand from the Quarto tutorial are:</p>
<ul>
<li>How to knit as word or pdf (pdf requires extra software installations)</li>
<li>Formatting, headings, bold etc…</li>
<li>YAML frontmatter for styles, linking a bibliography and bibliography style</li>
<li>How to insert images and/or code.</li>
</ul>
<p><strong>Note on AI integration</strong> once you are using quarto and Roo Code you can simply ask Roo Code to do things in your document (like outline a paper template) by referencing the file (e.g. <span class="citation" data-cites="myfile.qmd">@myfile.qmd</span>) in the prompt box.</p>
<p>Whether this works well for you is another questions. Prompting well requires a lot of thought and practice. Its not simply going to write a paper for you. You have to give the AI assistant detailed, specific, instructions and lots of context.</p>
</section>
<section id="yaml-front-matter" class="level3">
<h3 class="anchored" data-anchor-id="yaml-front-matter">6. YAML front matter</h3>
<p>The <code>YAML</code> controls how your qmd document is rendered. Here’s an example of mine:</p>
<pre><code>---
title: "The paper's title"
format: docx
editor: visual
bibliography: mybib.bib
csl: myjournal.csl
execute: 
  echo: false
  message: false
  warning: false
---</code></pre>
<p>This goes at the top of your document. A few key points.</p>
<p><code>format</code> controls document type to render this as, here a word doc.</p>
<p><code>editor</code> controls how it is viewed in vscode. Options are <code>editor: visual</code> and <code>editor: source</code>. Visual looks more like a word doc, source looks more like markdown. You’ll have to save and re-open the document for this to change.</p>
<p><code>bibliography</code> links to a bibtex file where your references are stored.</p>
<p><code>csl</code> links to a style guide for the bibliography.</p>
<p>More on styles and references below.</p>
<p><code>execute</code> is controlling how R code is run and if the R code appears in the document.</p>
</section>
<section id="rendering-as-a-document" class="level3">
<h3 class="anchored" data-anchor-id="rendering-as-a-document">7. Rendering as a document</h3>
<p>Use the short-cut key ‘cmd-shift-K’/‘cntrl-shft-k’ (mac/windows) to preview your document. It will also create a rendered version in your current directory.</p>
<p>Its helpful to set: <code>format: html</code> when you are writing the document, then you get a live preview in vscode. Use <code>format: docx</code> when you want a word document.</p>
<p>Its worth also learning the short-cut `cmd-shft-p’/‘cntrl-shft-p’, this brings up searchable actions for all extensions in vscode. The one you want is ‘Quarto: preview’ which does the same as the shortcut above.</p>
<p>I tend to have minimal R code in my quarto manuscript. Or none at all (just reference .png files for figures). This keeps rendering quick. Also your document can get unweildy if there is a lot of text mixed in with R code.</p>
</section>
<section id="word-counts" class="level3">
<h3 class="anchored" data-anchor-id="word-counts">8. Word counts</h3>
<p>There are various word count extensions for vscode qmd and md documents.</p>
</section>
<section id="document-styles" class="level3">
<h3 class="anchored" data-anchor-id="document-styles">9. Document styles</h3>
<p>Getting a word document to follow a particular style is a bit fiddly. You need to set-up a template word document with styles the include that as a reference in your YAML.</p>
<p><a href="https://quarto.org/docs/output-formats/ms-word-templates.html">See instructions here.</a></p>
</section>
<section id="reference-manager-integration" class="level3">
<h3 class="anchored" data-anchor-id="reference-manager-integration">10. Reference manager integration</h3>
<p>Quarto integrates with many different reference managers. <a href="https://quarto.org/docs/authoring/citations.html">There’s a good guide here</a>.</p>
<p>In brief you create a <code>.bib</code> file that has your references in it. This is then linked in the YAML. The manual way to manage this is just to create a <code>.bib</code> file and paste bibtext entries directly into it (available on most journal’s pages as a citation format, as well as google scholar).</p>
<p>e.g.&nbsp;the bibtext for R looks like this:</p>
<pre><code>@Manual{Rlanguage,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2024},
    url = {https://www.R-project.org/},
  }</code></pre>
<p>Then in quarto you just type <code>@</code> and a dropdown of all your references will appear. <code>@Manual{Rlanguage,</code> the Rlanguage bit is the CiteKey that will appear in the dropdown. So <code>@Rlanguage</code> will insert that reference into the bibliography and the citation at that place in the document.</p>
<p>You can streamline the process of gathering and managing references with a reference manager.</p>
<p>My workflow in Zotero is as follows:</p>
<ul>
<li>Open Zotero on my computer</li>
<li>Go to journal webpage for paper</li>
<li>Use zotero plugin to my browser to grab the citation and save it to a library</li>
<li>Go to my quarto document in VScode</li>
<li>type <code>@</code> and a drop down of all references in all libraries on zotero appears. Pick the one I want.</li>
<li>Click the <code>OK</code> button which saves that reference into my local <code>.bib</code> file.</li>
</ul>
<p>For some reason (that does not seem to be documented in any quarto tutorials anywhere!) it will find any reference I have anywhere in zotero and then save that bibtex entry to my local <code>.bib</code> file, so it is now accessible for use in my quarto doc. This only works if I have zotero open and use <code>editor: visual</code> in the YAML.</p>
<p>There are many other options however.</p>
</section>
<section id="optional-ai-integration-for-reference-management" class="level3">
<h3 class="anchored" data-anchor-id="optional-ai-integration-for-reference-management">11. Optional AI integration for reference management</h3>
<p>You can get AI assistants to help with referencing if you keep your notes on papers linked to your references. For instance, you could keep your notes on references in the bibtex field for <code>notes</code>. Alternatively you could create another quarto/markdown document that has a header for each citation tag along with its notes in a structured way:</p>
<pre><code>## Rlanguage 

### What it is

The R software for scientific computing. 

### Usage

Citation for the R software. Use this at least once in every paper where i've used R for statistics

## edgar2023continent

### What is it

Key paper that shows Australia is losing its marine biodiversity. 

### Usage

Cite this as evidence that Australia is losing coastal marine biodiversity and as evidence that climate change is causing marine biodiversity loss
</code></pre>
<p>It doesn’t matter how you do this, so long as you follow a consistent structure. I’ve used the CiteKey as the main header for each reference entry. Then I’ve put in markdown sections about each paper and why I might wnat to cite it. Then you can get Roo Code to help with inserting references.</p>
<p>Note that if you are using the <code>.bib</code> directly just be careful not to plagiarise! Roo Code might insert excerpts from the abstracts/titles directly into your written document, which is a no-no for publishing.</p>


</section>

 ]]></description>
  <category>rstats</category>
  <category>research-skills</category>
  <guid>https://www.seascapemodels.org/posts/2025-07-07-writing-papers-with-quarto/</guid>
  <pubDate>Sun, 06 Jul 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Prompting large language models for quality ecological statistics</title>
  <link>https://www.seascapemodels.org/posts/2025-06-27-prompting-llms-quality-ecological-statistics/</link>
  <description><![CDATA[ 





<p>Announcing a new <a href="https://ecoevorxiv.org/repository/view/9493/">pre-print on prompt engineering for ecological statistics.</a>. https://doi.org/10.32942/X2CS80</p>
<p>The pre-print describes the challenges and opportunities of using large language models and agents to do ecological statistics. It then goes onto describe some prompt engineering strategies that can help you make the most of these tools, but still get reliable statistical advice and code.</p>
<p>The pre-print accompanies <a href="https://www.seascapemodels.org/R-llm-workshop/index.html#summary">a one day course</a> I’ve published that teaches how to use LLM tools for R and statistics, as well as discussing the environmental and ethical challenges.</p>



 ]]></description>
  <category>rstats</category>
  <category>genAI</category>
  <guid>https://www.seascapemodels.org/posts/2025-06-27-prompting-llms-quality-ecological-statistics/</guid>
  <pubDate>Thu, 26 Jun 2025 14:00:00 GMT</pubDate>
</item>
<item>
  <title>Why we are all naturally Bayesians not frequentists</title>
  <link>https://www.seascapemodels.org/posts/2025-06-25-why-frequentist-statistics-makes-no-sense/</link>
  <description><![CDATA[ 





<p>I don’t see why its a thing to say “I’m a Bayesian”. Being a Bayesian is normal for any rational person as we will prove in a couple of sentences. Being a frequentist is what is what is strange. It would make more sense to assume we are all Bayesians, and have frequentists have to declare “I’m a frequentist”.</p>
<p>The statistical quantity of interest for frequentist is the likelihood, which is defined as the probability of your observations given your hypothesis. It can be written:</p>
<p><code>Pr(D | H)</code></p>
<p>(Equivalently probability of data given we assume a particular model). For a Bayesian the statistical quantity is the probability of the hypothesis given the observations or:</p>
<p><code>Pr(H | D)</code></p>
<p>(Equivalently probability of a model given the data).</p>
<p>Say we’re out on a boat and we catch a glance of a human sized animal dive underwater with a flap of its tail. Was it a mermaid or a dugong? (A dugong is type of seagrass eating mammal).</p>
<p>A frequentist would think in likelihoods and conclude, correctly, that both mermaid and dugong are equally likely: Both creatures, if assumed to exist, could result in a similar observation of us seeing a body and a tail diving underwater, i.e.</p>
<p><code>Pr(seeing a tail | dugongs exist) ≈ Pr(seeing a tail | mermaid exist)</code></p>
<p>A rational person would guess the observed tail was a dugong. That is because a rational person is thinking in terms of probabilities. The probability we observed a mermaid is vanishingly small, because all prior evidence leads us to believe that mermaids don’t exist (though I do know some less than rational people who believe in ‘merfolk’).</p>
<p>In logic, Bayes theorem says we can calculate the probability of the hypothesis</p>
<p><code>Pr(H | D) = Pr(D | H)*Pr(H) / Pr(D)</code></p>
<p>So for the hypothesis “it’s a dugong”:</p>
<p><code>Pr(dugong | seeing tail) = Pr(seeing tail | dugong)*Pr(dugong) / Pr(seeing tail)</code></p>
<p>For our two models, dugong versus mermaid, we have similar values for the likelihoods and <code>pr(D)</code>, but the ‘prior probabilities’, the <code>Pr(H)</code>, are very different. <code>Pr(dugong)</code> is plausible (even though is rare to see them), whereas <code>Pr(mermaid)</code> is zero, because merfolk don’t exist.</p>
<p>We multiply the likelihood by the prior in the Bayes equation, so the <code>Pr(mermaid | seeing tail)</code> becomes zero.</p>
<p>(If you are new to Bayes theory, you might be wondering what does <code>Pr(D)</code> mean? How do we calculate the probability of the data? For the above example it doesn’t matter as <code>Pr(seeing a tail)</code> is the same for both hypotheses. One of the challenges of Bayes stats in practice is calculating this <code>Pr(D)</code>. A lot of statistical computing is devoted to figuring out how to do that. In brief though <code>Pr(D)</code> can be calculated as the sum of <code>Pr(seeing tail | dugong)*Pr(H)</code> for all discrete hypotheses or the integral if our hypotheses are continuous (like parameter values)).</p>
<p>Does this philosophical distinction it matter in the practice of statistics?</p>
<p>The Bayesian version of an analysis, such as a GLM, will often given similar or the same predictions as the frequentist version. Yet ecology, like many other disciplines, has a problem with repeatability and p-hacking.</p>
<p>Part of the problem stems from the methods we use. For large sample sizes frequentist and Bayesian results often do converge.</p>
<p>But small sample sizes are common in many fields, including ecology. A small sample size study that finds an extreme and significant result is attractive to publish. This issue has been particularly problematic in <a href="https://www.nature.com/articles/s41586-019-1903-y">behavioural ecology</a>. These false positives come to dominate the literature.</p>
<p>Appropriate use of Bayesian priors would penalize these extreme effect sizes. This is equivalent to setting a low probability on mermaid sightings above. Some have <a href="https://xcelab.net/rm/">called for stronger priors to be the default choice</a></p>
<p>So in every day life we think of probabilities Bayesians, not like frequentists. There are numerous Bayesian R packages now and they are increasingly easy to use. So it makes sense that we should apply the same logic to our statistical analyses as well.</p>
<p>Thanks to Sober’s ‘Philosophy of Biology’ for this example (he uses gremlins in the roof rather than mermaids) and Coralina for telling me about the book!</p>



 ]]></description>
  <category>rstats</category>
  <category>research</category>
  <guid>https://www.seascapemodels.org/posts/2025-06-25-why-frequentist-statistics-makes-no-sense/</guid>
  <pubDate>Tue, 24 Jun 2025 14:00:00 GMT</pubDate>
</item>
</channel>
</rss>
